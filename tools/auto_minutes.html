<!DOCTYPE html>
<html lang="zh-HK">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Cantonese STT & Diarization</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body { -webkit-tap-highlight-color: transparent; font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; }
        .scrollable { overflow-y: auto; -webkit-overflow-scrolling: touch; }
        ::-webkit-scrollbar { width: 6px; }
        ::-webkit-scrollbar-track { background: #f1f1f1; border-radius: 4px; }
        ::-webkit-scrollbar-thumb { background: #cbd5e1; border-radius: 4px; }
        .glass-panel { background: rgba(255, 255, 255, 0.9); backdrop-filter: blur(12px); -webkit-backdrop-filter: blur(12px); border: 1px solid rgba(226, 232, 240, 0.8); }
        .speaker-1 { color: #2563eb; font-weight: 600; }
        .speaker-2 { color: #16a34a; font-weight: 600; }
        .speaker-unknown { color: #6b7280; font-weight: 600; }
    </style>
</head>
<body class="bg-slate-50 text-slate-800 h-screen flex flex-col overflow-hidden">

    <!-- Header -->
    <header class="bg-blue-600 text-white p-4 shadow-md flex justify-between items-center z-10 shrink-0">
        <div>
            <h1 class="text-xl md:text-2xl font-bold tracking-tight">Cantonese AI Transcriber</h1>
            <p class="text-blue-100 text-xs md:text-sm">Real-time STT & Diarization (WebGPU/WASM)</p>
        </div>
        <div class="bg-blue-700 px-3 py-1.5 rounded-full text-xs font-semibold flex items-center gap-2 shadow-inner">
            <span class="w-2.5 h-2.5 rounded-full bg-yellow-400 animate-pulse" id="status-indicator"></span>
            <span id="status-text">Awaiting Load</span>
        </div>
    </header>

    <!-- Main Content Area -->
    <main class="flex-1 flex flex-col md:flex-row gap-4 p-4 overflow-hidden">
        
        <!-- Left Panel: Controls & Dashboard -->
        <section class="w-full md:w-1/3 flex flex-col gap-4 shrink-0 overflow-y-auto scrollable pb-4">
            
            <!-- Settings Card -->
            <div class="glass-panel p-5 rounded-2xl shadow-sm">
                <h2 class="text-lg font-bold mb-4 border-b pb-2">Settings</h2>
                
                <div class="space-y-4">
                    <div>
                        <label class="block text-sm font-semibold mb-1 text-slate-600">STT Model</label>
                        <select id="model-select" class="w-full p-2.5 rounded-xl border border-slate-200 bg-white text-sm focus:ring-2 focus:ring-blue-500 outline-none">
                            <option value="Xenova/whisper-base">Whisper Base (~150MB - Faster)</option>
                            <option value="Xenova/whisper-small">Whisper Small (~450MB - Better)</option>
                        </select>
                    </div>

                    <div>
                        <label class="block text-sm font-semibold mb-1 text-slate-600">Mode</label>
                        <select id="mode-select" class="w-full p-2.5 rounded-xl border border-slate-200 bg-white text-sm focus:ring-2 focus:ring-blue-500 outline-none">
                            <option value="single">Single User (Faster)</option>
                            <option value="multi">Multi-Speaker (Diarization)</option>
                        </select>
                    </div>

                    <div>
                        <label class="block text-sm font-semibold mb-1 text-slate-600">Output Style</label>
                        <div class="flex bg-slate-100 p-1 rounded-xl">
                            <button id="style-colloquial" class="flex-1 py-2 text-sm font-medium rounded-lg bg-white shadow-sm text-blue-600 transition-all">Âè£Ë™û (Colloquial)</button>
                            <button id="style-formal" class="flex-1 py-2 text-sm font-medium rounded-lg text-slate-500 hover:text-slate-700 transition-all">Êõ∏Èù¢Ë™û (Formal)</button>
                        </div>
                    </div>
                </div>

                <button id="btn-load" class="w-full mt-6 bg-slate-800 text-white font-bold py-3.5 rounded-xl hover:bg-slate-700 active:scale-95 transition-all shadow-md">
                    Load AI Models
                </button>
            </div>

            <!-- Progress Dashboard -->
            <div id="progress-container" class="glass-panel p-5 rounded-2xl shadow-sm hidden">
                <div class="flex justify-between items-end mb-2">
                    <h3 class="text-sm font-bold text-slate-700">Downloading Models</h3>
                    <span id="progress-text" class="text-xs font-bold text-blue-600 bg-blue-50 px-2 py-1 rounded-md">0%</span>
                </div>
                <p id="progress-file" class="text-xs text-slate-500 truncate mb-3">Initializing AI engine...</p>
                
                <div class="w-full bg-slate-200 rounded-full h-2.5 overflow-hidden">
                    <div id="progress-bar" class="bg-blue-600 h-2.5 rounded-full transition-all duration-200 ease-out" style="width: 0%"></div>
                </div>
                <p id="error-message" class="text-xs text-red-500 mt-2 hidden font-medium"></p>
            </div>

            <!-- Main Actions -->
            <div class="glass-panel p-5 rounded-2xl shadow-sm flex flex-col gap-3">
                <button id="btn-start" disabled class="w-full bg-emerald-500 text-white font-bold py-4 rounded-xl opacity-50 cursor-not-allowed flex justify-center items-center gap-2 text-lg transition-all shadow-sm">
                    <svg class="w-6 h-6" fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM9.555 7.168A1 1 0 008 8v4a1 1 0 001.555.832l3-2a1 1 0 000-1.664l-3-2z" clip-rule="evenodd"></path></svg>
                    Start Recording
                </button>
                <button id="btn-stop" disabled class="hidden w-full bg-red-500 text-white font-bold py-4 rounded-xl flex justify-center items-center gap-2 text-lg transition-all shadow-sm hover:bg-red-600 active:scale-95">
                    <svg class="w-6 h-6" fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM8 7a1 1 0 00-1 1v4a1 1 0 001 1h4a1 1 0 001-1V8a1 1 0 00-1-1H8z" clip-rule="evenodd"></path></svg>
                    Stop Recording
                </button>
            </div>

            <!-- System Logs Panel -->
            <div class="glass-panel p-4 rounded-2xl shadow-sm flex flex-col h-48 shrink-0">
                <h3 class="text-sm font-bold text-slate-700 mb-2 border-b pb-1">System Logs</h3>
                <div id="log-box" class="flex-1 overflow-y-auto font-mono text-xs text-slate-600 space-y-1.5 bg-slate-100 p-2.5 rounded-xl border border-slate-200">
                    <!-- Logs will be injected here -->
                </div>
            </div>

        </section>

        <!-- Right Panel: Live Transcript & Post-Processing -->
        <section class="flex-1 flex flex-col gap-4 min-w-0">
            
            <!-- Live View -->
            <div class="glass-panel rounded-2xl shadow-sm flex-1 flex flex-col overflow-hidden relative border border-slate-200">
                <div class="border-b border-slate-200 p-4 flex justify-between items-center bg-white">
                    <h2 class="text-lg font-bold text-slate-800">Live Transcript</h2>
                    <span id="vad-indicator" class="px-2.5 py-1 bg-slate-100 text-slate-500 rounded-md text-xs font-mono font-medium transition-colors border border-slate-200">VAD: Standby</span>
                </div>
                <div id="transcript-box" class="flex-1 p-5 scrollable text-lg leading-relaxed space-y-3 bg-slate-50/50">
                    <p class="text-slate-400 text-sm text-center mt-10">Waiting for models to load...</p>
                </div>
            </div>

            <!-- Export Panel -->
            <div id="export-panel" class="glass-panel p-4 rounded-2xl shadow-sm hidden shrink-0">
                <h3 class="font-bold text-sm text-slate-700 mb-3 border-b pb-2">Export Data</h3>
                <div class="grid grid-cols-2 md:grid-cols-3 gap-2">
                    <button id="btn-export-txt" class="bg-white border border-slate-200 hover:bg-slate-50 text-slate-700 py-2.5 px-3 rounded-xl text-sm font-semibold transition-colors shadow-sm">üìÑ Export .txt</button>
                    <button id="btn-export-json" class="bg-white border border-slate-200 hover:bg-slate-50 text-slate-700 py-2.5 px-3 rounded-xl text-sm font-semibold transition-colors shadow-sm">üìä Export .json</button>
                    <button id="btn-export-audio" class="bg-white border border-slate-200 hover:bg-slate-50 text-slate-700 py-2.5 px-3 rounded-xl text-sm font-semibold transition-colors shadow-sm">üéµ Audio (.webm)</button>
                </div>
            </div>

        </section>
    </main>

    <!-- Web Worker Script -->
    <!-- Changed type to 'text/worker' to prevent the browser from executing it as main-thread JS -->
    <script id="worker-code" type="text/worker">
        import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.2.0';

        // Notify main thread that worker successfully loaded the library
        self.postMessage({ type: 'log', message: 'Transformers.js library loaded successfully.' });

        // Configure environment
        env.allowLocalModels = false;
        // Optimize WASM threads
        env.backends.onnx.wasm.numThreads = Math.min(navigator.hardwareConcurrency || 4, 4);

        let transcriber = null;
        let segmenter = null;

        // Track download progress for multiple files
        const downloadProgress = {};

        function reportProgress(info) {
            if (info.status === 'init') {
                downloadProgress[info.file] = 0; // Initialize at 0
                self.postMessage({ type: 'progress', status: 'init', file: info.file, name: info.name });
            } else if (info.status === 'progress') {
                downloadProgress[info.file] = info.progress;
            } else if (info.status === 'done') {
                downloadProgress[info.file] = 100;
            }

            // Always update UI state (fixes cached files or skipped updates)
            if (info.status === 'progress' || info.status === 'done') {
                const files = Object.values(downloadProgress);
                const totalProgress = files.reduce((acc, val) => acc + val, 0) / (files.length || 1);
                
                self.postMessage({ 
                    type: 'progress', 
                    status: 'downloading',
                    file: info.file, 
                    progress: totalProgress 
                });
            }
        }

        async function loadPipelineWithFallback(task, model, isQuantized) {
            self.postMessage({ type: 'log', message: `Attempting to load ${model}...` });
            
            // iPad/iOS Safari's experimental WebGPU frequently crashes the worker silently.
            // Bypassing WebGPU entirely on these devices prevents the "frozen at 0%" issue.
            const isIOS = /iPad|iPhone|iPod/.test(navigator.userAgent) || 
                          (navigator.userAgent.includes('Mac') && navigator.maxTouchPoints > 1);

            if (!isIOS) {
                try {
                    // Try WebGPU first on Desktop/Android
                    const pipe = await pipeline(task, model, {
                        device: 'webgpu',
                        dtype: isQuantized ? 'q4f16' : 'fp16',
                        progress_callback: reportProgress
                    });
                    self.postMessage({ type: 'log', message: `Successfully loaded ${model} via WebGPU.` });
                    return pipe;
                } catch (e) {
                    self.postMessage({ type: 'log', message: `WebGPU unavailable (${e.message}). Falling back to WASM.` });
                }
            } else {
                self.postMessage({ type: 'log', message: `iOS/iPadOS detected. Bypassing WebGPU to prevent silent crash.` });
            }
            
            // Fallback to WASM
            const pipe = await pipeline(task, model, {
                device: 'wasm',
                dtype: 'q8', // 8-bit quantization is safer for WASM memory limits
                progress_callback: reportProgress
            });
            self.postMessage({ type: 'log', message: `Successfully loaded ${model} via WASM.` });
            return pipe;
        }

        self.onmessage = async (e) => {
            const { type, data } = e.data;

            if (type === 'load_models') {
                try {
                    self.postMessage({ type: 'progress', status: 'start', file: 'Initializing environment...' });
                    
                    // 1. Load STT Model (Whisper)
                    transcriber = await loadPipelineWithFallback('automatic-speech-recognition', data.model, true);

                    // 2. Load Diarization Model if needed
                    if (data.mode === 'multi') {
                        self.postMessage({ type: 'progress', status: 'start', file: 'Loading Diarization Engine...' });
                        segmenter = await loadPipelineWithFallback('audio-frame-classification', 'Xenova/pyannote-segmentation-3.0', false);
                    }
                    
                    self.postMessage({ type: 'models_loaded' });
                } catch (error) {
                    self.postMessage({ type: 'error', message: "Failed to load AI models: " + error.message });
                }
            }
            
            else if (type === 'process_audio') {
                if (!transcriber) return;
                
                try {
                    const audioData = data.audio;
                    
                    // Run STT Inference
                    const sttResult = await transcriber(audioData, {
                        language: 'cantonese',
                        task: 'transcribe',
                        chunk_length_s: 30,
                    });

                    let speaker = "Unknown";
                    
                    // Run Diarization Inference
                    if (segmenter && data.mode === 'multi') {
                        const segResult = await segmenter(audioData);
                        if (segResult && segResult.length > 0) {
                            segResult.sort((a, b) => b.score - a.score);
                            const topLabel = segResult[0].label;
                            const spkNum = parseInt(topLabel.split('_')[1] || "0") + 1;
                            speaker = "Speaker " + spkNum;
                        }
                    } else if (data.mode === 'single') {
                        speaker = "Speaker 1";
                    }

                    self.postMessage({ 
                        type: 'transcript_chunk', 
                        text: sttResult.text, 
                        speaker: speaker,
                        timestamp: data.timestamp
                    });

                } catch (error) {
                    self.postMessage({ type: 'log', message: "Inference error: " + error.message });
                }
            }
        };
    </script>

    <!-- Application Logic -->
    <script>
        const ui = {
            modelSelect: document.getElementById('model-select'),
            modeSelect: document.getElementById('mode-select'),
            styleColloquial: document.getElementById('style-colloquial'),
            styleFormal: document.getElementById('style-formal'),
            btnLoad: document.getElementById('btn-load'),
            btnStart: document.getElementById('btn-start'),
            btnStop: document.getElementById('btn-stop'),
            progressContainer: document.getElementById('progress-container'),
            progressBar: document.getElementById('progress-bar'),
            progressText: document.getElementById('progress-text'),
            progressFile: document.getElementById('progress-file'),
            errorMessage: document.getElementById('error-message'),
            statusIndicator: document.getElementById('status-indicator'),
            statusText: document.getElementById('status-text'),
            transcriptBox: document.getElementById('transcript-box'),
            vadIndicator: document.getElementById('vad-indicator'),
            exportPanel: document.getElementById('export-panel'),
            btnExportTxt: document.getElementById('btn-export-txt'),
            btnExportJson: document.getElementById('btn-export-json'),
            btnExportAudio: document.getElementById('btn-export-audio'),
            logBox: document.getElementById('log-box')
        };

        const state = {
            outputStyle: 'colloquial',
            isRecording: false,
            transcriptData: [],
            audioChunks: [],
            startTime: 0
        };

        // Cantonese Mapping Dictionary
        const cantoneseDict = {
            '‰øÇ': 'ÊòØ', 'Âîî‰øÇ': '‰∏çÊòØ', '‰Ω¢': '‰ªñ', '‰Ω¢Âìã': '‰ªñÂÄë', 'ÊàëÂìã': 'ÊàëÂÄë', '‰Ω†Âìã': '‰Ω†ÂÄë',
            'ÂòÖ': 'ÁöÑ', 'Âñ∫': 'Âú®', 'ÂíÅ': 'ÈÄôÊ®£', 'Áùá': 'Áúã', 'Ë´ó': 'ÊÉ≥', 'È£ü': 'ÂêÉ', 'Âíó': '‰∫Ü', 
            'Á∑ä': 'Ê≠£Âú®', 'ÂÜá': 'Ê≤íÊúâ', 'ÁÑ°': 'Ê≤íÊúâ', 'Âöü': '‰æÜ', 'Èªé': '‰æÜ', 'Âï≤': '‰∫õ', 
            'Èùö': 'ÊºÇ‰∫Æ', 'ÁïÄ': 'Áµ¶', '‰øæ': 'Áµ¶', 'Êêµ': 'Êâæ', 'ÂÇæ': 'Ë´á', 'Â±ã‰ºÅ': 'ÂÆ∂', 
            'ËøîÂ≠∏': '‰∏äÂ≠∏', 'ËøîÂ∑•': '‰∏äÁè≠', 'ÈªûËß£': 'ÁÇ∫‰ªÄÈ∫º', 'ËÄåÂÆ∂': 'ÁèæÂú®', '‰ªäÊó•': '‰ªäÂ§©', 
            'ËÅΩÊó•': 'ÊòéÂ§©', 'Â∞ãÊó•': 'Êò®Â§©', 'Áê¥Êó•': 'Êò®Â§©', 'Âí©': '‰ªÄÈ∫º', 'Âò¢': 'Êù±Ë•ø'
        };

        function translateToFormal(text) {
            let result = text;
            for (const [canto, formal] of Object.entries(cantoneseDict)) {
                result = result.replace(new RegExp(canto, 'g'), formal);
            }
            return result;
        }

        // --- Logging & Capability Checks ---
        function addLog(message, type = 'info') {
            const time = new Date().toLocaleTimeString([], { hour12: false });
            const colors = {
                info: 'text-slate-600',
                success: 'text-emerald-600',
                error: 'text-red-600 font-bold',
                warn: 'text-amber-600'
            };
            const div = document.createElement('div');
            div.className = `break-words ${colors[type] || colors.info}`;
            div.innerHTML = `<span class="text-slate-400 select-none">[${time}]</span> ${message}`;
            ui.logBox.appendChild(div);
            ui.logBox.scrollTop = ui.logBox.scrollHeight;
        }

        function checkCapabilities() {
            addLog("Initializing system checks...", "info");
            
            if (navigator.onLine) addLog("Network: Online (Ready to download)", "success");
            else addLog("Network: Offline (Downloads will fail)", "error");

            if (typeof WebAssembly === "object") addLog("WebAssembly: Supported", "success");
            else addLog("WebAssembly: NOT Supported (Engine will fail)", "error");

            if (navigator.gpu) addLog("WebGPU: Supported (May use hardware accel)", "success");
            else addLog("WebGPU: Not Supported (Will use CPU/WASM fallback)", "warn");

            if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) addLog("Microphone API: Supported", "success");
            else addLog("Microphone API: Missing or blocked (Check HTTPS)", "error");
        }

        // Initialize Web Worker safely
        const blob = new Blob([document.getElementById('worker-code').textContent], { type: 'application/javascript' });
        const workerUrl = URL.createObjectURL(blob);
        const aiWorker = new Worker(workerUrl, { type: 'module' });

        // Catch and log worker initialization errors (e.g., failed to load CDN)
        aiWorker.onerror = (err) => {
            console.error("Worker Initialization Error: ", err);
            addLog(`Worker failed to start! (Check CDN/Network): ${err.message || 'CORS/Module Load Error'}`, "error");
            ui.btnLoad.innerText = "Load Failed - Retry";
            ui.btnLoad.disabled = false;
            ui.btnLoad.classList.replace('bg-slate-500', 'bg-red-600');
            ui.progressContainer.classList.add('hidden');
        };

        // Handle Worker Messages
        aiWorker.onmessage = (e) => {
            const { type, status, file, name, progress, message, text, speaker, timestamp } = e.data;

            switch (type) {
                case 'log':
                    console.log("[AI Engine]:", message);
                    addLog(`[Engine] ${message}`, 'info');
                    break;
                case 'progress':
                    ui.progressContainer.classList.remove('hidden');
                    
                    if (status === 'init') {
                        ui.progressFile.innerText = `Fetching metadata: ${file}`;
                        addLog(`Init model file: ${file}`, 'info');
                    } else if (status === 'start') {
                        ui.progressFile.innerText = file;
                        addLog(`Status: ${file}`, 'info');
                    } else if (status === 'downloading') {
                        // Extract just the filename to keep UI clean
                        const shortFile = file ? file.split('/').pop() : 'Weights';
                        ui.progressFile.innerText = `Downloading: ${shortFile}`;
                        
                        const pct = Math.min(100, Math.max(0, Math.round(progress)));
                        ui.progressBar.style.width = `${pct}%`;
                        ui.progressText.innerText = `${pct}%`;
                    }
                    break;
                case 'models_loaded':
                    ui.progressContainer.classList.add('hidden');
                    ui.statusIndicator.classList.replace('bg-yellow-400', 'bg-emerald-400');
                    ui.statusIndicator.classList.remove('animate-pulse');
                    ui.statusText.innerText = "Engine Ready";
                    addLog("All AI models loaded successfully!", "success");
                    
                    ui.btnLoad.classList.add('hidden');
                    ui.btnStart.disabled = false;
                    ui.btnStart.classList.remove('opacity-50', 'cursor-not-allowed');
                    ui.btnStart.classList.add('hover:bg-emerald-600', 'active:scale-95');
                    
                    ui.transcriptBox.innerHTML = '<p class="text-slate-400 text-sm text-center mt-10">Press Start Recording to begin.</p>';
                    break;
                case 'transcript_chunk':
                    if (!text || text.trim() === '') return;
                    
                    state.transcriptData.push({
                        timestamp: timestamp,
                        speaker: speaker,
                        colloquial: text.trim(),
                        formal: translateToFormal(text.trim())
                    });
                    
                    renderTranscript();
                    break;
                case 'error':
                    ui.errorMessage.innerText = message;
                    ui.errorMessage.classList.remove('hidden');
                    ui.btnLoad.innerText = "Retry Loading";
                    ui.btnLoad.disabled = false;
                    ui.btnLoad.classList.replace('bg-slate-500', 'bg-red-600');
                    console.error("Worker Error:", message);
                    addLog(`Fatal Error: ${message}`, 'error');
                    break;
            }
        };

        // Style Toggles
        function setStyle(style) {
            state.outputStyle = style;
            const isColloquial = style === 'colloquial';
            
            ui.styleColloquial.className = isColloquial 
                ? 'flex-1 py-2 text-sm font-medium rounded-lg bg-white shadow-sm text-blue-600 transition-all'
                : 'flex-1 py-2 text-sm font-medium rounded-lg text-slate-500 hover:text-slate-700 transition-all';
                
            ui.styleFormal.className = !isColloquial 
                ? 'flex-1 py-2 text-sm font-medium rounded-lg bg-white shadow-sm text-blue-600 transition-all'
                : 'flex-1 py-2 text-sm font-medium rounded-lg text-slate-500 hover:text-slate-700 transition-all';
                
            renderTranscript();
        }

        ui.styleColloquial.addEventListener('click', () => setStyle('colloquial'));
        ui.styleFormal.addEventListener('click', () => setStyle('formal'));

        function renderTranscript() {
            if (state.transcriptData.length === 0 && state.isRecording) {
                ui.transcriptBox.innerHTML = '<p class="text-slate-400 text-sm text-center mt-10">Listening...</p>';
                return;
            }

            ui.transcriptBox.innerHTML = '';
            state.transcriptData.forEach((item) => {
                const textToShow = state.outputStyle === 'colloquial' ? item.colloquial : item.formal;
                const spkClass = item.speaker === 'Speaker 1' ? 'speaker-1' : (item.speaker === 'Speaker 2' ? 'speaker-2' : 'speaker-unknown');
                
                const div = document.createElement('div');
                div.className = 'bg-white p-3.5 rounded-xl shadow-sm border border-slate-100 flex gap-3 animate-fade-in';
                div.innerHTML = `
                    <div class="text-xs text-slate-400 font-mono pt-1 shrink-0 w-10">${formatTime(item.timestamp)}</div>
                    <div>
                        <span class="${spkClass} text-sm mr-2">${item.speaker}:</span>
                        <span class="text-slate-800">${textToShow}</span>
                    </div>
                `;
                ui.transcriptBox.appendChild(div);
            });
            ui.transcriptBox.scrollTop = ui.transcriptBox.scrollHeight;
        }

        function formatTime(seconds) {
            const mins = Math.floor(seconds / 60);
            const secs = Math.floor(seconds % 60);
            return `${mins}:${secs.toString().padStart(2, '0')}`;
        }

        // Audio Processing Logic
        let audioContext, mediaStream, mediaRecorder, processor, analyser;
        let pcmDataBuffer = [];
        const VAD_THRESHOLD = 0.005; // iPad mics are sensitive
        const SAMPLE_RATE = 16000;
        const CHUNK_MS = 3000; // Dispatch every 3s

        async function startRecording() {
            try {
                addLog("Requesting microphone permission...", "info");
                mediaStream = await navigator.mediaDevices.getUserMedia({ audio: { echoCancellation: true, noiseSuppression: true } });
                addLog("Microphone access granted.", "success");
                audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: SAMPLE_RATE });
                
                mediaRecorder = new MediaRecorder(mediaStream, { mimeType: 'audio/webm' });
                mediaRecorder.ondataavailable = (e) => { if (e.data.size > 0) state.audioChunks.push(e.data); };
                mediaRecorder.start(1000);

                const source = audioContext.createMediaStreamSource(mediaStream);
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 512;
                
                processor = audioContext.createScriptProcessor(4096, 1, 1);
                source.connect(analyser);
                analyser.connect(processor);
                processor.connect(audioContext.destination);

                let chunkTimer = 0;
                let activeAudio = false;

                processor.onaudioprocess = (e) => {
                    if (!state.isRecording) return;
                    
                    const inputData = e.inputBuffer.getChannelData(0);
                    
                    // Simple Root Mean Square (RMS) for Voice Activity Detection
                    let sumSquares = 0;
                    for (let i = 0; i < inputData.length; i++) sumSquares += inputData[i] * inputData[i];
                    const rms = Math.sqrt(sumSquares / inputData.length);
                    const isVoiced = rms > VAD_THRESHOLD;
                    
                    if (isVoiced && !activeAudio) {
                        ui.vadIndicator.innerText = "VAD: Speech";
                        ui.vadIndicator.classList.replace('bg-slate-100', 'bg-emerald-100');
                        ui.vadIndicator.classList.replace('text-slate-500', 'text-emerald-700');
                        activeAudio = true;
                    } else if (!isVoiced && activeAudio) {
                        ui.vadIndicator.innerText = "VAD: Silence";
                        ui.vadIndicator.classList.replace('bg-emerald-100', 'bg-slate-100');
                        ui.vadIndicator.classList.replace('text-emerald-700', 'text-slate-500');
                        activeAudio = false;
                    }

                    if (isVoiced || pcmDataBuffer.length > 0) {
                        pcmDataBuffer.push(new Float32Array(inputData));
                    }

                    chunkTimer += (inputData.length / SAMPLE_RATE) * 1000;
                    if (chunkTimer >= CHUNK_MS) {
                        if (pcmDataBuffer.length > 0) sendChunkToWorker();
                        chunkTimer = 0;
                    }
                };

                state.isRecording = true;
                state.startTime = audioContext.currentTime;
                state.transcriptData = [];
                state.audioChunks = [];
                
                // Update UI state
                ui.btnStart.classList.add('hidden');
                ui.btnStop.classList.remove('hidden');
                ui.btnStop.disabled = false;
                
                ui.statusIndicator.classList.replace('bg-emerald-400', 'bg-red-500');
                ui.statusIndicator.classList.add('animate-pulse');
                ui.statusText.innerText = "Recording...";
                ui.exportPanel.classList.add('hidden');
                addLog("Recording session started.", "success");

                renderTranscript();

            } catch (err) {
                addLog(`Microphone access denied: ${err.message}`, "error");
                alert("Microphone access is required to transcribe audio. " + err.message);
            }
        }

        function sendChunkToWorker() {
            const totalLength = pcmDataBuffer.reduce((acc, val) => acc + val.length, 0);
            const flatBuffer = new Float32Array(totalLength);
            let offset = 0;
            for (let chunk of pcmDataBuffer) {
                flatBuffer.set(chunk, offset);
                offset += chunk.length;
            }
            
            aiWorker.postMessage({
                type: 'process_audio',
                data: {
                    audio: flatBuffer,
                    timestamp: audioContext.currentTime - state.startTime,
                    mode: ui.modeSelect.value
                }
            });

            pcmDataBuffer = [];
        }

        function stopRecording() {
            if (!state.isRecording) return;
            state.isRecording = false;

            if (pcmDataBuffer.length > 0) sendChunkToWorker();

            mediaRecorder.stop();
            processor.disconnect();
            analyser.disconnect();
            audioContext.close();
            mediaStream.getTracks().forEach(t => t.stop());

            ui.btnStop.classList.add('hidden');
            ui.btnStart.classList.remove('hidden');
            
            ui.statusIndicator.classList.remove('animate-pulse', 'bg-red-500');
            ui.statusIndicator.classList.add('bg-emerald-400');
            ui.statusText.innerText = "Engine Ready";
            ui.vadIndicator.innerText = "VAD: Standby";
            ui.vadIndicator.classList.replace('bg-emerald-100', 'bg-slate-100');
            ui.vadIndicator.classList.replace('text-emerald-700', 'text-slate-500');
            
            ui.exportPanel.classList.remove('hidden');
        }

        // Setup Button Listeners
        ui.btnLoad.addEventListener('click', () => {
            ui.btnLoad.innerText = "Initializing...";
            ui.btnLoad.disabled = true;
            ui.btnLoad.classList.add('bg-slate-500');
            ui.progressContainer.classList.remove('hidden');
            ui.errorMessage.classList.add('hidden');
            ui.progressFile.innerText = "Waking up AI engine...";
            addLog(`Sending load command to AI Engine (${ui.modelSelect.value})...`, "info");
            
            aiWorker.postMessage({
                type: 'load_models',
                data: {
                    model: ui.modelSelect.value,
                    mode: ui.modeSelect.value
                }
            });
        });

        ui.btnStart.addEventListener('click', startRecording);
        ui.btnStop.addEventListener('click', stopRecording);

        // Export Actions
        ui.btnExportTxt.addEventListener('click', () => {
            const textContent = state.transcriptData.map(item => 
                `[${formatTime(item.timestamp)}] ${item.speaker}: ${state.outputStyle === 'colloquial' ? item.colloquial : item.formal}`
            ).join('\n');
            downloadBlob(new Blob([textContent], { type: 'text/plain' }), 'transcript.txt');
        });

        ui.btnExportJson.addEventListener('click', () => {
            downloadBlob(new Blob([JSON.stringify(state.transcriptData, null, 2)], { type: 'application/json' }), 'transcript.json');
        });

        ui.btnExportAudio.addEventListener('click', () => {
            downloadBlob(new Blob(state.audioChunks, { type: 'audio/webm' }), 'recording.webm');
        });

        function downloadBlob(blob, filename) {
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.style.display = 'none';
            a.href = url;
            a.download = filename;
            document.body.appendChild(a);
            a.click();
            window.URL.revokeObjectURL(url);
            addLog(`Exported file: ${filename}`, "success");
        }

        // Custom animation
        tailwind.config = {
            theme: { extend: { animation: { 'fade-in': 'fadeIn 0.4s ease-out forwards' }, keyframes: { fadeIn: { '0%': { opacity: '0', transform: 'translateY(8px)' }, '100%': { opacity: '1', transform: 'translateY(0)' } } } } }
        };

        // Run capability checks on startup
        checkCapabilities();
        addLog("Application ready. Waiting for user to load models.", "info");
    </script>
</body>
</html>
